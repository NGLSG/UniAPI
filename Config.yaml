openAi:
  enable: true
  api_key: ""
  model: gpt-4o
  proxy: ""
  useWebProxy: false
  endPoint: ""
  supportModels:
    [ "gpt-4o","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-16k","gpt-3.5-turbo-0613","gpt-3.5-turbo-16k-0613","gpt-4-0613","gpt-4o-0613" ]
claude:
  enable: false
  channelID: ""
  userName: ""
  cookies: ""
  slackToken: ""
  supportModels:
    [ ]
gemini:
  enable: false
  api_Key: ""
  endPoint: ""
  model: gemini-2.0-flash
  supportModels:
    [ "gemini-2.5-pro-preview-03-25","gemini-2.5-flash-preview-04-17","gemini-2.0-flash-exp","gemini-2.0-flash" ]
grok:
  enable: false
  api_key: ""
  model: ""
  apiHost: ""
  apiPath: ""
  useLocalModel: false
  llamaData:
    model: ""
    contextSize: 32000
    maxTokens: 4096
  supportModels:
    [ "grok-1.0","grok-1.5","grok-2.0" ]
mistral:
  enable: false
  api_key: ""
  model: ""
  apiHost: ""
  apiPath: ""
  useLocalModel: false
  llamaData:
    model: ""
    contextSize: 32000
    maxTokens: 4096
  supportModels:
    [ ]
qwen:
  enable: false
  api_key: ""
  model: ""
  apiHost: ""
  apiPath: ""
  useLocalModel: false
  llamaData:
    model: ""
    contextSize: 32000
    maxTokens: 4096
  supportModels:
    [ ]
chatglm:
  enable: false
  api_key: ""
  model: ""
  apiHost: ""
  apiPath: ""
  useLocalModel: false
  llamaData:
    model: ""
    contextSize: 32000
    maxTokens: 4096
  supportModels:
    [ ]
hunyuan:
  enable: false
  api_key: ""
  model: ""
  apiHost: ""
  apiPath: ""
  useLocalModel: false
  llamaData:
    model: ""
    contextSize: 32000
    maxTokens: 4096
  supportModels:
    [ ]
baichuan:
  enable: false
  api_key: ""
  model: ""
  apiHost: ""
  apiPath: ""
  useLocalModel: false
  llamaData:
    model: ""
    contextSize: 32000
    maxTokens: 4096
  supportModels:
    [ ]
sparkdesk:
  enable: false
  api_key: ""
  model: ""
  apiHost: ""
  apiPath: ""
  useLocalModel: false
  llamaData:
    model: ""
    contextSize: 32000
    maxTokens: 4096
  supportModels:
    [ ]
huoshan:
  enable: false
  api_key: ""
  model: ""
  apiHost: ""
  apiPath: ""
  useLocalModel: false
  llamaData:
    model: ""
    contextSize: 32000
    maxTokens: 4096
  supportModels:
    [ ]
claudeAPI:
  enable: false
  apiKey: ""
  model: claude-3.5
  apiVersion: 2023-06-01
  endPoint: https://api.anthropic.com/v1/complete
  supportModels:
    [ "claude-1","claude-2","claude-3","claude-3.5","claude-3.7-sonnet" ]
customGPTs:
  { }
customRules:
  [ ]