# ğŸŒŸ UniAPI ğŸŒ

<div align="center">
  <h3>é€šç”¨LLM APIé›†æˆå·¥å…·åŒ… | ä¸‡èƒ½ãªLLM APIçµ±åˆãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ | Universal LLM API Integration Toolkit</h3>
  <p><i>"ä¸€ä¸ªæ ‡å‡†è°ƒç”¨æ‰€æœ‰ | å…¨ã¦ã‚’å‘¼ã³å‡ºã™ä¸€ã¤ã®æ¨™æº– | One Standard to Call Them All"</i></p>

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![C++20](https://img.shields.io/badge/C++-20%2B-00599C?logo=c%2B%2B)](https://en.cppreference.com/w/cpp/compiler_support)
[![CUDA](https://img.shields.io/badge/CUDA-Optional-76B900?logo=nvidia)](https://developer.nvidia.com/cuda-toolkit)
</div>

---

## ğŸ“– è¯­è¨€é€‰æ‹© | è¨€èªé¸æŠ | Language Selection
- [ä¸­æ–‡ç‰ˆ](#ä¸­æ–‡ç‰ˆ)
- [æ—¥æœ¬èªç‰ˆ](#æ—¥æœ¬èªç‰ˆ)
- [English Version](#english-version)

---

<a id="ä¸­æ–‡ç‰ˆ"></a>
## ä¸­æ–‡ç‰ˆ

### ğŸ” æ¦‚è¿°

UniAPI æ˜¯ä¸€ä¸ª**é«˜æ€§èƒ½ C++ åº“**ï¼Œå®ƒå°† 50 å¤šä¸ª LLM API ç»Ÿä¸€åˆ°ä¸€ä¸ª**OpenAI å…¼å®¹çš„ REST æœåŠ¡å™¨**ä¸­ã€‚è¯¥åº“è®¾è®¡ç”¨äºå¿«é€Ÿéƒ¨ç½²ï¼Œé»˜è®¤æƒ…å†µä¸‹**æ— éœ€èº«ä»½éªŒè¯**ï¼Œæ”¯æŒåŠ¨æ€åŠ è½½æä¾›è€…ï¼Œå¹¶ä¸”å¯ä»¥ç›´æ¥æ¨ç†æœ¬åœ°é‡åŒ– GGML æ¨¡å‹ï¼Œæ— éœ€é¢å¤–é…ç½®ã€‚

```bash
# é€šè¿‡ OpenAI æ ‡å‡†ç«¯ç‚¹è°ƒç”¨ä»»ä½• LLM
curl -X POST http://localhost:8080/v1/chat/completions \
Â  -H "Content-Type: application/json" \
Â  -d '{"model":"claude-3","messages":[{"role":"user","content":"ä½ å¥½ï¼"}]}'
```

### ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆæ— éœ€è®¤è¯ï¼‰

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨ Dockerï¼ˆæ¨èï¼‰

##### 1. æ„å»º Docker é•œåƒ

```bash
# å…‹éš†ä»“åº“
git clone --recursive https://github.com/NGLSG/UniAPI.git
cd UniAPI

# æ„å»º Docker é•œåƒ
docker build -t uniapi:latest .
```

##### 2. è¿è¡Œ Docker å®¹å™¨

```bash
# ä½¿ç”¨é»˜è®¤ç«¯å£ (8080) è¿è¡Œ
docker run -it --rm -p 8080:8080 uniapi:latest

# ä½¿ç”¨è‡ªå®šä¹‰ç«¯å£è¿è¡Œ
docker run -it --rm -e PORT=9090 -p 9090:9090 uniapi:latest

# æŒ‚è½½è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
docker run -it --rm -p 8080:8080 -v $(pwd)/Config.yaml:/app/Config.yaml uniapi:latest
```

#### æ–¹æ³•äºŒï¼šæœ¬åœ°ç¼–è¯‘å®‰è£…

##### 1. å…‹éš†ä»“åº“åŠå­æ¨¡å—

```bash
git clone --recursive https://github.com/NGLSG/UniAPI.git
cd UniAPI
# å¦‚æœå­æ¨¡å—æœªæ‹‰å–ï¼š
git submodule update --init --recursive
```

##### 2. å®‰è£…ä¾èµ–é¡¹

```bash
# Ubuntu/Debian ç³»ç»Ÿ
sudo apt-get update
sudo apt-get install -y \
Â  Â  git cmake build-essential \
Â  Â  libvulkan-dev curl libcurl4-openssl-dev \
Â  Â  libjsoncpp-dev uuid-dev libssl-dev zlib1g-dev
Â  Â Â 
# å¯é€‰æ•°æ®åº“æ”¯æŒ
sudo apt-get install -y \
Â  Â  libmysqlclient-dev \
Â  Â  libsqlite3-dev \
Â  Â  libhiredis-dev

# CentOS/RHEL ç³»ç»Ÿ
sudo yum install -y \
Â  Â  git cmake gcc-c++ \
Â  Â  vulkan-devel curl libcurl-devel \
Â  Â  jsoncpp-devel libuuid-devel openssl-devel zlib-devel
Â  Â Â 
# å¯é€‰æ•°æ®åº“æ”¯æŒ
sudo yum install -y \
Â  Â  mysql-devel sqlite-devel hiredis-devel
```

##### 3. ç¼–è¯‘é¡¹ç›®

```bash
mkdir build && cd build
cmake .. \
Â  -DCMAKE_CUDA_COMPILER=[CUDA_DIR]/bin/nvcc \Â  # å¯é€‰ CUDA ç¼–è¯‘å™¨
Â  -DCMAKE_TOOLCHAIN_FILE=[vcpkg_dir]/scripts/buildsystems/vcpkg.cmakeÂ  # å¦‚æœä½¿ç”¨ vcpkg
make -j4
```

##### 4. è¿è¡ŒæœåŠ¡å™¨

```bash
./bin/UniAPI 8080Â  # ç«¯å£å¯ä»¥æ›´æ”¹
```

â¡ï¸ **ç«‹å³æµ‹è¯•**è®¿é—® `http://<your_ip>:8080/v1/chat/completions`

### âš™ï¸ ä¸»è¦ç‰¹æ€§

| ç‰¹æ€§ | æè¿° |
|------|------|
| **ğŸ”“ é›¶è®¤è¯** | é»˜è®¤æ— éœ€ API å¯†é’¥ |
| **âš¡ å¿«é€Ÿæ¨ç†** | æ”¯æŒ GPU åŠ é€Ÿçš„å¯é€‰ CUDA |
| **ğŸ“¦ æœ¬åœ°é‡åŒ–æ¨¡å‹** | ç›´æ¥æ¨ç†æœ¬åœ°é‡åŒ– GGML æ¨¡å‹ï¼Œæ— éœ€é¢å¤–é…ç½® |
| **ğŸ“¡ REST æ ‡å‡†** | 100% å…¼å®¹ OpenAI æ ‡å‡†ç«¯ç‚¹ |
| **ğŸ”„ åŠ¨æ€é…ç½®** | é€šè¿‡ `Config.yaml` çµæ´»é…ç½® API |
| **ğŸ”Œ è‡ªå®šä¹‰æä¾›è€…** | ä½¿ç”¨è§„åˆ™é€‚é…ä»»æ„æ¥å£ï¼Œå®ç°é«˜åº¦æ‰©å±•æ€§ |

### ğŸ“¦ æ”¯æŒçš„åç«¯

| æä¾›å•† | æè¿° |
|--------|------|
| **OpenAI** | GPT-3.5ã€GPT-4 æ¨¡å‹ |
| **Claude** | Claude-1ã€Claude-2ã€Claude-3 æ¨¡å‹ |
| **Gemini** | Google Gemini 1.5 æ¨¡å‹ |
| **GGML æ¨¡å‹** | æœ¬åœ°é‡åŒ–æ¨¡å‹ç›´æ¥æ¨ç† |
| **å…¶ä»–** | ä½¿ç”¨è§„åˆ™é€‚é…å‡ ä¹ä»»ä½•æ¥å£ |

### ğŸ”§ é…ç½®ç¤ºä¾‹ï¼šè‡ªå®šä¹‰æä¾›è€…

```yaml
- enable: false
  supportSystemRole: true
  name: æµ‹è¯•2
  model: o3-mini
  apiPath: http://localhost:3032/v1/chat/completions
  apiKeyRole:
    key: nuul
    role: HEADERS
    header: "Authorization: Bearer "
  headers:
    header2: 1
    anthropic-version: "\"2023-06-01\""
  roles:
    system: system
    user: user
    assistant: assistant
  promptRole:
    role:
      suffix: messages
      path: role
      content: content
      isStr: false
    prompt:
      suffix: messages
      path: content
      content: content
      isStr: false
  params:
    - suffix: stream
      path: ""
      content: true
      isStr: false
    - suffix: model
      path: ""
      content: ${MODEL}
      isStr: true
  responseRole:
    suffix: ""
    content: result/message/content
    callback: RESPONSE
    stopFlag: ""
  author: Ryoshi
  version: 1.0
  description: è‡ªå®šä¹‰è§„åˆ™
  supportModels: []
```

### ğŸ“œ è®¸å¯è¯

MIT - å…è´¹ç”¨äºå•†ä¸šå’Œä¸ªäººç”¨é€”ã€‚è¯¦è§ [LICENSE](LICENSE)ã€‚

---

<a id="æ—¥æœ¬èªç‰ˆ"></a>
## æ—¥æœ¬èªç‰ˆ

### ğŸ” æ¦‚è¦

UniAPI ã¯ã€50 ä»¥ä¸Šã® LLM API ã‚’å˜ä¸€ã® **OpenAI äº’æ› REST ã‚µãƒ¼ãƒãƒ¼** ã«çµ±åˆã™ã‚‹ **é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãª C++ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª** ã§ã™ã€‚è¿…é€Ÿãªå±•é–‹ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ **èªè¨¼ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“** ã—ã€å‹•çš„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ãƒ­ãƒ¼ãƒ‰ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚¯ã‚ªãƒ³ã‚¿ã‚¤ã‚ºã•ã‚ŒãŸ GGML ãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥æ¨è«–ã§ãã€è¿½åŠ ã®è¨­å®šã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚

```bash
# OpenAI æ¨™æº–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’çµŒç”±ã—ã¦ä»»æ„ã® LLM ã«ã‚¢ã‚¯ã‚»ã‚¹
curl -X POST http://localhost:8080/v1/chat/completions \
Â  -H "Content-Type: application/json" \
Â  -d '{"model":"claude-3","messages":[{"role":"user","content":"ã“ã‚“ã«ã¡ã¯ï¼"}]}'
```

### ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆèªè¨¼ãªã—ï¼‰

#### æ–¹æ³• 1ï¼šDocker ã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰

##### 1. Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ã®æ§‹ç¯‰

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
git clone --recursive https://github.com/NGLSG/UniAPI.git
cd UniAPI

# Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ã®æ§‹ç¯‰
docker build -t uniapi:latest .
```

##### 2. Docker ã‚³ãƒ³ãƒ†ãƒŠã®å®Ÿè¡Œ

```bash
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒ¼ãƒˆ (8080) ã§å®Ÿè¡Œ
docker run -it --rm -p 8080:8080 uniapi:latest

# ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ¼ãƒˆã§å®Ÿè¡Œ
docker run -it --rm -e PORT=9090 -p 9090:9090 uniapi:latest

# ã‚«ã‚¹ã‚¿ãƒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¦ãƒ³ãƒˆ
docker run -it --rm -p 8080:8080 -v $(pwd)/Config.yaml:/app/Config.yaml uniapi:latest
```

#### æ–¹æ³• 2ï¼šãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«

##### 1. ãƒªãƒã‚¸ãƒˆãƒªã¨ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¯ãƒ­ãƒ¼ãƒ³

```bash
git clone --recursive https://github.com/NGLSG/UniAPI.git
cd UniAPI
# ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå–å¾—ã•ã‚Œã¦ã„ãªã„å ´åˆï¼š
git submodule update --init --recursive
```

##### 2. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install -y \
Â  Â  git cmake build-essential \
Â  Â  libvulkan-dev curl libcurl4-openssl-dev \
Â  Â  libjsoncpp-dev uuid-dev libssl-dev zlib1g-dev
Â  Â Â 
# ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µãƒãƒ¼ãƒˆ
sudo apt-get install -y \
Â  Â  libmysqlclient-dev \
Â  Â  libsqlite3-dev \
Â  Â  libhiredis-dev

# CentOS/RHELÂ 
sudo yum install -y \
Â  Â  git cmake gcc-c++ \
Â  Â  vulkan-devel curl libcurl-devel \
Â  Â  jsoncpp-devel libuuid-devel openssl-devel zlib-devel
Â  Â Â 
# ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µãƒãƒ¼ãƒˆ
sudo yum install -y \
Â  Â  mysql-devel sqlite-devel hiredis-devel
```

##### 3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«

```bash
mkdir build && cd build
cmake .. \
Â  -DCMAKE_CUDA_COMPILER=[CUDA_DIR]/bin/nvcc \Â  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã® CUDA ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©
Â  -DCMAKE_TOOLCHAIN_FILE=[vcpkg_dir]/scripts/buildsystems/vcpkg.cmakeÂ  # vcpkg ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
make -j4
```

##### 4. ã‚µãƒ¼ãƒãƒ¼ã®å®Ÿè¡Œ

```bash
./bin/UniAPI 8080Â  # ãƒãƒ¼ãƒˆã¯å¤‰æ›´å¯èƒ½
```

â¡ï¸ **ã™ãã«ãƒ†ã‚¹ãƒˆ**ï¼š`http://<your_ip>:8080/v1/chat/completions` ã«ã‚¢ã‚¯ã‚»ã‚¹

### âš™ï¸ ä¸»ãªæ©Ÿèƒ½

| æ©Ÿèƒ½ | èª¬æ˜ |
|------|------|
| **ğŸ”“ èªè¨¼ä¸è¦** | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ API ã‚­ãƒ¼ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ |
| **âš¡ é«˜é€Ÿæ¨è«–** | ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã® CUDA ã‚µãƒãƒ¼ãƒˆã§ GPU ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ |
| **ğŸ“¦ ãƒ­ãƒ¼ã‚«ãƒ«ã‚¯ã‚ªãƒ³ã‚¿ã‚¤ã‚ºãƒ¢ãƒ‡ãƒ«** | ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚¯ã‚ªãƒ³ã‚¿ã‚¤ã‚ºã•ã‚ŒãŸ GGML ãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥æ¨è«– |
| **ğŸ“¡ REST æ¨™æº–** | OpenAI æ¨™æº–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ã‚µãƒãƒ¼ãƒˆ |
| **ğŸ”„ å‹•çš„æ§‹æˆ** | `Config.yaml` ã‚’é€šã˜ã¦ API ã‚’æŸ”è»Ÿã«æ§‹æˆ |
| **ğŸ”Œ ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼** | ä»»æ„ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ãƒ«ãƒ¼ãƒ«ã§é©å¿œã—ã€é«˜ã„æ‹¡å¼µæ€§ã‚’å®Ÿç¾ |

### ğŸ“¦ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰

| ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ | èª¬æ˜ |
|--------------|------|
| **OpenAI** | GPT-3.5ã€GPT-4 ãƒ¢ãƒ‡ãƒ« |
| **Claude** | Claude-1ã€Claude-2ã€Claude-3 ãƒ¢ãƒ‡ãƒ« |
| **Gemini** | Google Gemini 1.5 ãƒ¢ãƒ‡ãƒ« |
| **GGML ãƒ¢ãƒ‡ãƒ«** | ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚¯ã‚ªãƒ³ã‚¿ã‚¤ã‚ºã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ç›´æ¥æ¨è«– |
| **ãã®ä»–** | ä»»æ„ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ãƒ«ãƒ¼ãƒ«ã§æ§‹æˆ |

### ğŸ”§ è¨­å®šä¾‹ï¼šã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼

```yaml
- enable: false
  supportSystemRole: true
  name: æµ‹è¯•2
  model: o3-mini
  apiPath: http://localhost:3032/v1/chat/completions
  apiKeyRole:
    key: nuul
    role: HEADERS
    header: "Authorization: Bearer "
  headers:
    header2: 1
    anthropic-version: "\"2023-06-01\""
  roles:
    system: system
    user: user
    assistant: assistant
  promptRole:
    role:
      suffix: messages
      path: role
      content: content
      isStr: false
    prompt:
      suffix: messages
      path: content
      content: content
      isStr: false
  params:
    - suffix: stream
      path: ""
      content: true
      isStr: false
    - suffix: model
      path: ""
      content: ${MODEL}
      isStr: true
  responseRole:
    suffix: ""
    content: result/message/content
    callback: RESPONSE
    stopFlag: ""
  author: Ryoshi
  version: 1.0
  description: è‡ªå®šä¹‰è§„åˆ™
  supportModels: []
```

### ğŸ“œ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT - å•†ç”¨ãŠã‚ˆã³å€‹äººåˆ©ç”¨ã¯ç„¡æ–™ã§ã™ã€‚è©³ç´°ã¯ [LICENSE](LICENSE) ã‚’ã”ç¢ºèªãã ã•ã„ã€‚

---

<a id="english-version"></a>
## English Version

### ğŸ” Overview

UniAPI is a **high-performance C++ library** that consolidates 50+ LLM APIs into a single **OpenAI-compatible REST server**. Designed for rapid deployment, it operates **without authentication** by default, supports dynamic provider loading, and enables direct inference of local quantized GGML models without additional configuration.

```bash
# Access any LLM via OpenAI-standard endpoint
curl -X POST http://localhost:8080/v1/chat/completions \
Â  -H "Content-Type: application/json" \
Â  -d '{"model":"claude-3","messages":[{"role":"user","content":"Hello!"}]}'
```

### ğŸš€ Quick Start (No Auth)

#### Method 1: Using Docker (Recommended)

##### 1. Build Docker Image

```bash
# Clone repository
git clone --recursive https://github.com/NGLSG/UniAPI.git
cd UniAPI

# Build Docker image
docker build -t uniapi:latest .
```

##### 2. Run Docker Container

```bash
# Run with default port (8080)
docker run -it --rm -p 8080:8080 uniapi:latest

# Run with custom port
docker run -it --rm -e PORT=9090 -p 9090:9090 uniapi:latest

# Mount custom config file
docker run -it --rm -p 8080:8080 -v $(pwd)/Config.yaml:/app/Config.yaml uniapi:latest
```

#### Method 2: Local Compilation

##### 1. Clone Repository with Submodules

```bash
git clone --recursive https://github.com/NGLSG/UniAPI.git
cd UniAPI
# If submodules weren't pulled:
git submodule update --init --recursive
```

##### 2. Install Dependencies

```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install -y \
Â  Â  git cmake build-essential \
Â  Â  libvulkan-dev curl libcurl4-openssl-dev \
Â  Â  libjsoncpp-dev uuid-dev libssl-dev zlib1g-dev
Â  Â Â 
# Optional database support
sudo apt-get install -y \
Â  Â  libmysqlclient-dev \
Â  Â  libsqlite3-dev \
Â  Â  libhiredis-dev

# CentOS/RHELÂ 
sudo yum install -y \
Â  Â  git cmake gcc-c++ \
Â  Â  vulkan-devel curl libcurl-devel \
Â  Â  jsoncpp-devel libuuid-devel openssl-devel zlib-devel
Â  Â Â 
# Optional database support
sudo yum install -y \
Â  Â  mysql-devel sqlite-devel hiredis-devel
```

##### 3. Compile Project

```bash
mkdir build && cd build
cmake .. \
Â  -DCMAKE_CUDA_COMPILER=[CUDA_DIR]/bin/nvcc \Â  # Optional CUDA compiler
Â  -DCMAKE_TOOLCHAIN_FILE=[vcpkg_dir]/scripts/buildsystems/vcpkg.cmakeÂ  # If using vcpkg
make -j4
```

##### 4. Run Server

```bash
./bin/UniAPI 8080Â  # Port can be changed
```

â¡ï¸ **Immediately test** at `http://<your_ip>:8080/v1/chat/completions`

### âš™ï¸ Key Features

| Feature | Description |
|---------|-------------|
| **ğŸ”“ Zero Auth** | No API key required by default |
| **âš¡ Fast Inference** | Optional CUDA support for GPU acceleration |
| **ğŸ“¦ Local Quantized Models** | Direct inference of local quantized GGML models without extra configuration |
| **ğŸ“¡ REST Standard** | 100% compatible with OpenAI endpoints |
| **ğŸ”„ Dynamic Configuration** | Flexible API configuration via `Config.yaml` |
| **ğŸ”Œ Custom Providers** | Adapt to any interface using rule-based configuration |

### ğŸ“¦ Supported Backends

| Provider | Description |
|----------|-------------|
| **OpenAI** | GPT-3.5, GPT-4 models |
| **Claude** | Claude-1, Claude-2, Claude-3 models |
| **Gemini** | Google Gemini 1.5 models |
| **GGML Models** | Direct inference of local quantized models |
| **Others** | Configure any interface using rules |

### ğŸ”§ Configuration Example: Custom Provider

```yaml
- enable: false
  supportSystemRole: true
  name: æµ‹è¯•2
  model: o3-mini
  apiPath: http://localhost:3032/v1/chat/completions
  apiKeyRole:
    key: nuul
    role: HEADERS
    header: "Authorization: Bearer "
  headers:
    header2: 1
    anthropic-version: "\"2023-06-01\""
  roles:
    system: system
    user: user
    assistant: assistant
  promptRole:
    role:
      suffix: messages
      path: role
      content: content
      isStr: false
    prompt:
      suffix: messages
      path: content
      content: content
      isStr: false
  params:
    - suffix: stream
      path: ""
      content: true
      isStr: false
    - suffix: model
      path: ""
      content: ${MODEL}
      isStr: true
  responseRole:
    suffix: ""
    content: result/message/content
    callback: RESPONSE
    stopFlag: ""
  author: Ryoshi
  version: 1.0
  description: è‡ªå®šä¹‰è§„åˆ™
  supportModels: []
```

### ğŸ“œ License

MIT - Free for commercial and personal use. See [LICENSE](LICENSE).