# -*- coding: utf-8 -*-
# ğŸŒŸ UniAPI ğŸŒ

<div align="center">
  <h3>é€šç”¨LLM APIé›†æˆå·¥å…·åŒ… | ä¸‡èƒ½ãªLLM APIçµ±åˆãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ | Universal LLM API Integration Toolkit</h3>
  <p><i>"ä¸€ä¸ªæ ‡å‡†è°ƒç”¨æ‰€æœ‰ | å…¨ã¦ã‚’å‘¼ã³å‡ºã™ä¸€ã¤ã®æ¨™æº– | One Standard to Call Them All"</i></p>
  
  [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
  [![C++20](https://img.shields.io/badge/C++-20%2B-00599C?logo=c%2B%2B)](https://en.cppreference.com/w/cpp/compiler_support)
  [![CUDA](https://img.shields.io/badge/CUDA-Optional-76B900?logo=nvidia)](https://developer.nvidia.com/cuda-toolkit)
</div>

---

## ğŸ“– è¯­è¨€é€‰æ‹© | è¨€èªé¸æŠ | Language Selection
- [ä¸­æ–‡ç‰ˆ](#ä¸­æ–‡ç‰ˆ)
- [æ—¥æœ¬èªç‰ˆ](#æ—¥æœ¬èªç‰ˆ)
- [English Version](#english-version)

---

<a id="ä¸­æ–‡ç‰ˆ"></a>
## ä¸­æ–‡ç‰ˆ

### ğŸ” æ¦‚è¿°

UniAPI æ˜¯ä¸€ä¸ª**é«˜æ€§èƒ½ C++ åº“**ï¼Œå®ƒå°† 50 å¤šä¸ª LLM API ç»Ÿä¸€åˆ°å•ä¸ª **OpenAI å…¼å®¹çš„ REST æœåŠ¡å™¨**ä¸­ã€‚è¯¥åº“è®¾è®¡ç”¨äºå¿«é€Ÿéƒ¨ç½²ï¼Œé»˜è®¤æƒ…å†µä¸‹**ä¸éœ€è¦èº«ä»½éªŒè¯**ï¼Œå¹¶æ”¯æŒåŠ¨æ€æä¾›è€…åŠ è½½ã€‚

```bash
# é€šè¿‡ OpenAI æ ‡å‡†ç«¯ç‚¹è®¿é—®ä»»ä½• LLM
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"claude-3","messages":[{"role":"user","content":"ä½ å¥½ï¼"}]}'
```

### ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆæ— éœ€è®¤è¯ï¼‰

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨ Dockerï¼ˆæ¨èï¼‰

##### 1. æ„å»º Docker é•œåƒ

```bash
# å…‹éš†ä»“åº“
git clone --recursive https://github.com/NGLSG/UniAPI.git
cd UniAPI

# æ„å»º Docker é•œåƒ
docker build -t uniapi:latest .
```

##### 2. è¿è¡Œ Docker å®¹å™¨

```bash
# ä½¿ç”¨é»˜è®¤ç«¯å£ (8080) è¿è¡Œ
docker run -it --rm -p 8080:8080 uniapi:latest

# ä½¿ç”¨è‡ªå®šä¹‰ç«¯å£è¿è¡Œ
docker run -it --rm -e PORT=9090 -p 9090:9090 uniapi:latest

# æŒ‚è½½è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
docker run -it --rm -p 8080:8080 -v $(pwd)/Config.yaml:/app/Config.yaml uniapi:latest
```

#### æ–¹æ³•äºŒï¼šæœ¬åœ°ç¼–è¯‘å®‰è£…

##### 1. å…‹éš†ä»“åº“åŠå­æ¨¡å—

```bash
git clone --recursive https://github.com/NGLSG/UniAPI.git
cd UniAPI
# å¦‚æœå­æ¨¡å—æœªæ‹‰å–ï¼š
git submodule update --init --recursive
```

##### 2. å®‰è£…ä¾èµ–é¡¹

```bash
# Ubuntu/Debian ç³»ç»Ÿ
sudo apt-get update
sudo apt-get install -y git cmake build-essential libboost-all-dev libvulkan-dev curl libasio-dev libcurl4-openssl-dev

# CentOS/RHEL ç³»ç»Ÿ
sudo yum install -y git cmake gcc-c++ boost-devel vulkan-devel curl asio-devel libcurl-devel
```

##### 3. ç¼–è¯‘é¡¹ç›®

```bash
mkdir build && cd build
cmake .. \
  -DCROW_USE_BOOST=1 \          # ä¸º Crow HTTP å¯ç”¨ Boost
  -DCMAKE_CUDA_COMPILER=[CUDA_DIR]/bin/nvcc \  # å¯é€‰ CUDA ç¼–è¯‘å™¨
  -DCMAKE_TOOLCHAIN_FILE=[vcpkg_dir]/scripts/buildsystems/vcpkg.cmake  # å¦‚æœä½¿ç”¨ vcpkg
make -j4
```

##### 4. è¿è¡ŒæœåŠ¡å™¨

```bash
./bin/UniAPI 8080  # ç«¯å£å¯ä»¥æ›´æ”¹
```

â¡ï¸ **ç«‹å³æµ‹è¯•**è®¿é—® `http://<your_ip>:8080/v1/chat/completions`

### âš™ï¸ ä¸»è¦ç‰¹æ€§

| ç‰¹æ€§ | æè¿° |
|------|------|
| **ğŸ”“ é›¶è®¤è¯** | é»˜è®¤æƒ…å†µä¸‹ä¸éœ€è¦ API å¯†é’¥ |
| **âš¡ å¿«é€Ÿæ¨ç†** | å¯é€‰ CUDA æ”¯æŒï¼Œç”¨äº GPU åŠ é€Ÿ |
| **ğŸ“¡ REST æ ‡å‡†** | 100% OpenAI å…¼å®¹ç«¯ç‚¹ï¼ˆå³ä½¿å¯¹äºé OpenAI æ¨¡å‹ï¼‰|
| **ğŸ”„ é…ç½®** | ç¼–è¾‘ 'Config.yaml' æ¥é…ç½®ä½ çš„ API |

### ğŸ“¦ æ”¯æŒçš„åç«¯

| æä¾›å•† | æè¿° |
|--------|------|
| **OpenAI** | OpenAI çš„ GPT-3.5 å’Œ GPT-4 æ¨¡å‹ |
| **Claude** | Anthropic çš„ Claude-1ã€2 å’Œ 3 æ¨¡å‹ |
| **OpenAI-Interface** | ç”¨äºè‡ªå®šä¹‰æ¨¡å‹çš„ OpenAI API æ¥å£ |
| **Gemini** | æ¥è‡ª Google çš„ Gemini 1.5 æ¨¡å‹ |
| **å…¶ä»–** | ä½¿ç”¨è§„åˆ™é€‚é…å‡ ä¹ä»»ä½•æ¥å£ |

### ğŸ”§ é…ç½®

ç¼–è¾‘ `Config.yaml` æ–‡ä»¶æ¥è®¾ç½®ä½ çš„æä¾›å•†ã€‚å¦‚æœä½ æƒ³ä½¿ç”¨ GUI è¿›è¡Œé…ç½®ï¼Œå¯ä»¥ä½¿ç”¨ [ChatBot](https://github.com/NGLSG/ChatBot) é¡¹ç›®è½»æ¾é…ç½® `Config.yaml` æ–‡ä»¶ï¼ˆé…ç½®å®Œæˆåï¼Œä½ å¯ä»¥åœ¨ ChatBot å¯æ‰§è¡Œæ–‡ä»¶çš„åŒä¸€ç›®å½•ä¸‹æ‰¾åˆ° config.yamlï¼Œé€‚å½“ä¿®æ”¹åå¯åº”ç”¨äºæœ¬é¡¹ç›®ï¼‰ã€‚

ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ [ChatBot](https://github.com/NGLSG/ChatBot) é¡¹ç›®ï¼Œå®ƒéå¸¸æ–¹ä¾¿åœ°ä¸ LLM èŠå¤©ã€‚

### ğŸ“œ è®¸å¯è¯

MIT - å…è´¹ç”¨äºå•†ä¸šå’Œä¸ªäººç”¨é€”ã€‚è¯¦è§ [LICENSE](LICENSE)ã€‚

---

<a id="æ—¥æœ¬èªç‰ˆ"></a>
## æ—¥æœ¬èªç‰ˆ

### ğŸ” æ¦‚è¦

UniAPIã¯ã€50ä»¥ä¸Šã®LLM APIã‚’å˜ä¸€ã®**OpenAIäº’æ›RESTã‚µãƒ¼ãƒãƒ¼**ã«çµ±åˆã™ã‚‹**é«˜æ€§èƒ½C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒª**ã§ã™ã€‚è¿…é€Ÿãªå±•é–‹ã®ãŸã‚ã«è¨­è¨ˆã•ã‚Œã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯**èªè¨¼ä¸è¦**ã§ã€å‹•çš„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ãƒ­ãƒ¼ãƒ‰ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

```bash
# OpenAIæ¨™æº–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä»‹ã—ã¦ä»»æ„ã®LLMã«ã‚¢ã‚¯ã‚»ã‚¹
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"claude-3","messages":[{"role":"user","content":"ã“ã‚“ã«ã¡ã¯ï¼"}]}'
```

### ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆèªè¨¼ãªã—ï¼‰

#### æ–¹æ³•1ï¼šDockerã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰

##### 1. Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã®æ§‹ç¯‰

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
git clone --recursive https://github.com/NGLSG/UniAPI.git
cd UniAPI

# Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã®æ§‹ç¯‰
docker build -t uniapi:latest .
```

##### 2. Dockerã‚³ãƒ³ãƒ†ãƒŠã®å®Ÿè¡Œ

```bash
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒ¼ãƒˆï¼ˆ8080ï¼‰ã§å®Ÿè¡Œ
docker run -it --rm -p 8080:8080 uniapi:latest

# ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ¼ãƒˆã§å®Ÿè¡Œ
docker run -it --rm -e PORT=9090 -p 9090:9090 uniapi:latest

# ã‚«ã‚¹ã‚¿ãƒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¦ãƒ³ãƒˆ
docker run -it --rm -p 8080:8080 -v $(pwd)/Config.yaml:/app/Config.yaml uniapi:latest
```

#### æ–¹æ³•2ï¼šãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«

##### 1. ãƒªãƒã‚¸ãƒˆãƒªã¨ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¯ãƒ­ãƒ¼ãƒ³

```bash
git clone --recursive https://github.com/NGLSG/UniAPI.git
cd UniAPI
# ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå–å¾—ã•ã‚Œã¦ã„ãªã„å ´åˆï¼š
git submodule update --init --recursive
```

##### 2. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install -y git cmake build-essential libboost-all-dev libvulkan-dev curl libasio-dev libcurl4-openssl-dev

# CentOS/RHEL
sudo yum install -y git cmake gcc-c++ boost-devel vulkan-devel curl asio-devel libcurl-devel
```

##### 3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«

```bash
mkdir build && cd build
cmake .. \
  -DCROW_USE_BOOST=1 \          # Crow HTTPã®ãŸã‚ã®Boostæœ‰åŠ¹åŒ–
  -DCMAKE_CUDA_COMPILER=[CUDA_DIR]/bin/nvcc \  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®CUDAã‚³ãƒ³ãƒ‘ã‚¤ãƒ©
  -DCMAKE_TOOLCHAIN_FILE=[vcpkg_dir]/scripts/buildsystems/vcpkg.cmake  # vcpkgã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
make -j4
```

##### 4. ã‚µãƒ¼ãƒãƒ¼ã®å®Ÿè¡Œ

```bash
./bin/UniAPI 8080  # ãƒãƒ¼ãƒˆã¯å¤‰æ›´å¯èƒ½
```

â¡ï¸ **ã™ãã«ãƒ†ã‚¹ãƒˆ**ï¼š`http://<your_ip>:8080/v1/chat/completions`ã«ã‚¢ã‚¯ã‚»ã‚¹

### âš™ï¸ ä¸»ãªæ©Ÿèƒ½

| æ©Ÿèƒ½ | èª¬æ˜ |
|------|------|
| **ğŸ”“ èªè¨¼ä¸è¦** | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§APIã‚­ãƒ¼ä¸è¦ |
| **âš¡ é«˜é€Ÿæ¨è«–** | GPUã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³CUDAã‚µãƒãƒ¼ãƒˆ |
| **ğŸ“¡ RESTæ¨™æº–** | 100% OpenAIäº’æ›ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆéOpenAIãƒ¢ãƒ‡ãƒ«ã§ã‚‚ï¼‰ |
| **ğŸ”„ è¨­å®š** | 'Config.yaml'ã‚’ç·¨é›†ã—ã¦APIã‚’è¨­å®š |

### ğŸ“¦ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰

| ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ | èª¬æ˜ |
|--------------|------|
| **OpenAI** | OpenAIã®GPT-3.5ãŠã‚ˆã³GPT-4ãƒ¢ãƒ‡ãƒ« |
| **Claude** | Anthropicã®Claude-1ã€2ã€3ãƒ¢ãƒ‡ãƒ« |
| **OpenAI-Interface** | ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ç”¨ã®OpenAI APIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ |
| **Gemini** | Googleã®Gemini 1.5ãƒ¢ãƒ‡ãƒ« |
| **ãã®ä»–** | ãƒ«ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã»ã¼ã©ã‚“ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«ã‚‚é©å¿œ |

### ğŸ”§ è¨­å®š

`Config.yaml`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¦ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’è¨­å®šã—ã¾ã™ã€‚GUIã§è¨­å®šã—ãŸã„å ´åˆã¯ã€[ChatBot](https://github.com/NGLSG/ChatBot)ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨ã—ã¦`Config.yaml`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç°¡å˜ã«è¨­å®šã§ãã¾ã™ï¼ˆè¨­å®šå®Œäº†å¾Œã€ChatBotå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«config.yamlãŒè¦‹ã¤ã‹ã‚Šã€é©åˆ‡ãªä¿®æ­£ã‚’æ–½ã—ã¦ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«é©ç”¨ã§ãã¾ã™ï¼‰ã€‚

ã¾ãŸã€[ChatBot](https://github.com/NGLSG/ChatBot)ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€LLMã¨ã®ãƒãƒ£ãƒƒãƒˆãŒéå¸¸ã«ä¾¿åˆ©ã«ãªã‚Šã¾ã™ã€‚

### ğŸ“œ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT - å•†ç”¨ãŠã‚ˆã³å€‹äººåˆ©ç”¨ã¯ç„¡æ–™ã€‚è©³ç´°ã¯[LICENSE](LICENSE)ã‚’ã”è¦§ãã ã•ã„ã€‚

---

<a id="english-version"></a>
## English Version

### ğŸ” Overview

UniAPI is a **high-performance C++ library** that unifies 50+ LLM APIs into a single **OpenAI-compatible REST server**. Designed for rapid deployment, it requires **no authentication** by default and supports dynamic provider loading.

```bash
# Access any LLM via OpenAI-standard endpoint
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"claude-3","messages":[{"role":"user","content":"Hello!"}]}'
```

### ğŸš€ Quick Start (No Auth)

#### Method 1: Using Docker (Recommended)

##### 1. Build Docker Image

```bash
# Clone repository
git clone --recursive https://github.com/NGLSG/UniAPI.git
cd UniAPI

# Build Docker image
docker build -t uniapi:latest .
```

##### 2. Run Docker Container

```bash
# Run with default port (8080)
docker run -it --rm -p 8080:8080 uniapi:latest

# Run with custom port
docker run -it --rm -e PORT=9090 -p 9090:9090 uniapi:latest

# Mount custom config file
docker run -it --rm -p 8080:8080 -v $(pwd)/Config.yaml:/app/Config.yaml uniapi:latest
```

#### Method 2: Local Compilation

##### 1. Clone Repository with Submodules

```bash
git clone --recursive https://github.com/NGLSG/UniAPI.git
cd UniAPI
# If submodules weren't pulled:
git submodule update --init --recursive
```

##### 2. Install Dependencies

```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install -y git cmake build-essential libboost-all-dev libvulkan-dev curl libasio-dev libcurl4-openssl-dev

# CentOS/RHEL
sudo yum install -y git cmake gcc-c++ boost-devel vulkan-devel curl asio-devel libcurl-devel
```

##### 3. Compile Project

```bash
mkdir build && cd build
cmake .. \
  -DCROW_USE_BOOST=1 \          # Enable Boost for Crow HTTP
  -DCMAKE_CUDA_COMPILER=[CUDA_DIR]/bin/nvcc \  # Optional CUDA compiler
  -DCMAKE_TOOLCHAIN_FILE=[vcpkg_dir]/scripts/buildsystems/vcpkg.cmake  # If using vcpkg
make -j4
```

##### 4. Run Server

```bash
./bin/UniAPI 8080  # Port can be changed
```

â¡ï¸ **Immediately test** at `http://<your_ip>:8080/v1/chat/completions`

### âš™ï¸ Key Features

| Feature | Description |
|---------|-------------|
| **ğŸ”“ Zero Auth** | No API key required by default |
| **âš¡ Fast Inference** | Optional CUDA support for GPU-accelerated providers |
| **ğŸ“¡ REST Standard** | 100% OpenAI-compatible endpoints (even for non-OpenAI models) |
| **ğŸ”„ Configure** | Edit the 'Config.yaml' to configure your API |

### ğŸ“¦ Supported Backends

| Provider | Description |
|----------|-------------|
| **OpenAI** | OpenAI's GPT-3.5 and GPT-4 models |
| **Claude** | Anthropic's Claude-1, 2, and 3 models |
| **OpenAI-Interface** | OpenAI's API interface for custom models |
| **Gemini** | Gemini 1.5 models from Google |
| **Other** | Use rules to adapt to almost any interface |

### ğŸ”§ Configuration

Edit the `Config.yaml` file to set up your providers. If you want to use GUI to configure, you can use the [ChatBot](https://github.com/NGLSG/ChatBot) project to easily configure the `Config.yaml` file (After the configuration is completed, you can find config.yaml in the same directory as the ChatBot executable file, and the appropriate modification can be applied to this project).

You can also use the [ChatBot](https://github.com/NGLSG/ChatBot) project, which is very convenient for chatting with LLMs.

### ğŸ“œ License

MIT - Free for commercial and personal use. See [LICENSE](LICENSE).